{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing K nearest neighbors algorithm\n",
    "\n",
    "This code will apply the K Nearest Neighbors algorithm (KNN) to the IMDB Dataset based on vectors computed using TF-IDF\n",
    "We will use a training set of size 20000 for each class (i.e. 20k positive and 20k negative reviews)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "## Un comment this lines the first time you run the code\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./normalized_TF_IDF_matrix.pckl', 'rb') as f:\n",
    "    normalized_TF_IDF_matrix = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0038498 , -0.0038498 , -0.0038498 , ..., -0.0038498 ,\n",
       "        -0.0038498 ,  0.09975314],\n",
       "       [-0.003268  , -0.003268  , -0.003268  , ..., -0.003268  ,\n",
       "        -0.003268  , -0.003268  ],\n",
       "       [-0.00354295, -0.00354295, -0.00354295, ..., -0.00354295,\n",
       "        -0.00354295, -0.00354295],\n",
       "       ...,\n",
       "       [-0.003316  , -0.003316  , -0.003316  , ..., -0.003316  ,\n",
       "        -0.003316  , -0.003316  ],\n",
       "       [-0.00366195, -0.00366195, -0.00366195, ..., -0.00366195,\n",
       "        -0.00366195, -0.00366195],\n",
       "       [-0.00298504, -0.00298504, -0.00298504, ..., -0.00298504,\n",
       "        -0.00298504, -0.00298504]], shape=(50000, 2000))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_TF_IDF_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.0000000000000007)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(normalized_TF_IDF_matrix[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./IMDB_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training set and test set\n",
    "positive_Ix = list(data[data['sentiment']==\"positive\"].index)\n",
    "negative_Ix = list(data[data['sentiment']==\"negative\"].index)\n",
    "\n",
    "train_Ix = np.concatenate([positive_Ix[:20000], negative_Ix[:20000]])\n",
    "test_Ix = np.concatenate([positive_Ix[20000:], negative_Ix[20000:]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39969, 39970, 39974, 39976, 39978, 39979, 39980, 39981, 39983,\n",
       "       39985])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Ix[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = normalized_TF_IDF_matrix[train_Ix, :]\n",
    "test_vectors = normalized_TF_IDF_matrix[test_Ix, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0038498 , -0.0038498 , -0.0038498 , ..., -0.0038498 ,\n",
       "        -0.0038498 ,  0.09975314],\n",
       "       [-0.003268  , -0.003268  , -0.003268  , ..., -0.003268  ,\n",
       "        -0.003268  , -0.003268  ],\n",
       "       [-0.00354295, -0.00354295, -0.00354295, ..., -0.00354295,\n",
       "        -0.00354295, -0.00354295],\n",
       "       ...,\n",
       "       [-0.00234925, -0.00234925, -0.00234925, ..., -0.00234925,\n",
       "        -0.00234925, -0.00234925],\n",
       "       [-0.00397128, -0.00397128, -0.00397128, ..., -0.00397128,\n",
       "        -0.00397128, -0.00397128],\n",
       "       [-0.0029042 , -0.0029042 , -0.0029042 , ..., -0.0029042 ,\n",
       "        -0.0029042 , -0.0029042 ]], shape=(40000, 2000))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00509787, -0.00509787, -0.00509787, ..., -0.00509787,\n",
       "        -0.00509787, -0.00509787],\n",
       "       [-0.00373814, -0.00373814, -0.00373814, ..., -0.00373814,\n",
       "        -0.00373814, -0.00373814],\n",
       "       [-0.00449679, -0.00449679, -0.00449679, ..., -0.00449679,\n",
       "        -0.00449679, -0.00449679],\n",
       "       ...,\n",
       "       [-0.003316  , -0.003316  , -0.003316  , ..., -0.003316  ,\n",
       "        -0.003316  , -0.003316  ],\n",
       "       [-0.00366195, -0.00366195, -0.00366195, ..., -0.00366195,\n",
       "        -0.00366195, -0.00366195],\n",
       "       [-0.00298504, -0.00298504, -0.00298504, ..., -0.00298504,\n",
       "        -0.00298504, -0.00298504]], shape=(10000, 2000))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_train_test_vectors = np.dot(train_vectors, test_vectors.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_from_test_to_train = 1 - np.abs(cosine_train_test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./distances_from_test_to_train.pckl', 'wb') as f:\n",
    "    pickle.dump(distances_from_test_to_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98374036, 0.98699907, 0.98797618, ..., 0.93380536, 0.98259355,\n",
       "       0.99487187], shape=(40000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distances_from_test_to_train[:, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
